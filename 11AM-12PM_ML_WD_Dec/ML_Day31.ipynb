{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd7d86c4-c391-4665-93e8-04cadd12f4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reinforcement Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "57f7b68a-f6de-47b3-8e66-0574a036e13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basics of Q-Learning\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "86feb31a-4c69-40fa-8aa0-83d992eedbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# state :-   0,1,2,3\n",
    "n_states = 4\n",
    "n_actions = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "0a8ae794-c025-490c-8d03-32311797038a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = np.zeros((n_states,n_actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "6f8f83ca-23f4-4430-bf27-24a0a1afd546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.]])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "72fe9195-0152-4bc4-82ee-42637607288d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter\n",
    "learning_rate = 0.80\n",
    "discount_factor = 0.90\n",
    "episodes = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "4c6790d8-052a-4c2e-aeba-42ef8a027b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for episode in range(episodes):\n",
    "    # set the state\n",
    "    state = 0  # start with 0\n",
    "    while state!=3:  # Until Goal\n",
    "        # choose random action\n",
    "        action = random.randint(0,1)\n",
    "        # Next State Logic\n",
    "        if action==1:   # right\n",
    "            next_state = min(state+1 , 3)\n",
    "        else:          # left\n",
    "            next_state = max(state-1 , 0)\n",
    "        # Reward\n",
    "        if next_state == 3:\n",
    "            reward = 10\n",
    "        else:\n",
    "            reward = 1\n",
    "        Q[state , action] = Q[state,action]+ learning_rate * ( reward + discount_factor * np.max(Q[state,action]) - Q[state,action] )\n",
    "        state = next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "29465367-d319-4226-b8af-ee0eb7164881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q-Table-Learning\n",
      "[[ 9.99999992  9.99999999]\n",
      " [ 9.99997562  9.99999721]\n",
      " [ 9.9883369  99.97607881]\n",
      " [ 0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Q-Table-Learning\")\n",
    "print( Q )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "7f6145dd-0e3c-4c1f-92cc-712fceff74f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "91a66ee5-a3b3-454f-8460-cf307b15c7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "84851388-9d14-4d5f-94bb-f2414296f06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent Path : \n",
      "State : 0 , Action : 1\n",
      "State : 1 , Action : 1\n",
      "State : 2 , Action : 1\n",
      "Reached Goal\n"
     ]
    }
   ],
   "source": [
    "print(\"Agent Path : \")\n",
    "while state != 3:\n",
    "    # Select the best action\n",
    "    action = np.argmax( Q[state] )\n",
    "    print(f\"State : {state} , Action : {action}\")\n",
    "    if action == 1 :    # right\n",
    "        state = min(state+1 , 3)\n",
    "    else:               # left\n",
    "        state = max(state-1 , 0)\n",
    "print(\"Reached Goal\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
